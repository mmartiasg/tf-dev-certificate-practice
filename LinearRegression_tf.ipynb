{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement linear regression on tensorflow with gradient tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = \"datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATASETS+os.sep+\"winequality-red.csv\", \"r\") as file:\n",
    "    raw_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = raw_data.split(\"\\n\")[1:]\n",
    "columns = raw_data.split(\"\\n\")[0].split(\",\")\n",
    "\n",
    "N_ROWS = len(raw_dataset)\n",
    "N_FEATURES = len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed acidity',\n",
       " 'volatile acidity',\n",
       " 'citric acid',\n",
       " 'residual sugar',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'total sulfur dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol',\n",
       " 'quality']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROWS:  1599\n",
      "Features:  12\n"
     ]
    }
   ],
   "source": [
    "print(\"ROWS: \", N_ROWS)\n",
    "print(\"Features: \", N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.zeros((N_ROWS, N_FEATURES))\n",
    "\n",
    "i = 0\n",
    "for row in raw_dataset:\n",
    "    j = 0\n",
    "    for feature in row.split(\",\"):\n",
    "        dataset[i][j] = float(feature)\n",
    "        j+=1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9978 ,  3.51   ,  0.56   ,  9.4    ,  5.     ],\n",
       "       [ 0.9968 ,  3.2    ,  0.68   ,  9.8    ,  5.     ],\n",
       "       [ 0.997  ,  3.26   ,  0.65   ,  9.8    ,  5.     ],\n",
       "       ...,\n",
       "       [ 0.99574,  3.42   ,  0.75   , 11.     ,  6.     ],\n",
       "       [ 0.99547,  3.57   ,  0.71   , 10.2    ,  5.     ],\n",
       "       [ 0.99549,  3.39   ,  0.66   , 11.     ,  6.     ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:, 7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SEQ_FEATURES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 64.00 GB\n",
      "maxCacheSize: 24.00 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 19:26:52.771245: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-22 19:26:52.771403: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.constant(dataset[:, :N_SEQ_FEATURES], dtype=\"float32\")\n",
    "y_train = tf.constant(dataset[:, -1], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into train and validation\n",
    "\n",
    "into 70/30\n",
    "\n",
    "- Shuffle dataset\n",
    "- Select N for Train and N for Validation base on the proportio 70/20/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataset = np.random.shuffle(dataset)\n",
    "N_train = int(dataset.shape[0]*0.7)+1\n",
    "N_val = int(dataset.shape[0]*0.2)+1\n",
    "N_test = dataset.shape[0]-N_train-N_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows:  1120\n",
      "Validation rows:  320\n",
      "Test rows:  159\n"
     ]
    }
   ],
   "source": [
    "print(\"Train rows: \", N_train)\n",
    "print(\"Validation rows: \", N_val)\n",
    "print(\"Test rows: \", N_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data \n",
    "Into \n",
    "- Train\n",
    "- Val\n",
    "- Test \n",
    "\n",
    "And X for features and y for the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = dataset[:N_train, :N_SEQ_FEATURES]\n",
    "train_y = dataset[:N_train, -1]\n",
    "\n",
    "val_X = dataset[:N_val, :N_SEQ_FEATURES]\n",
    "val_y = dataset[:N_val, -1]\n",
    "\n",
    "test_X = dataset[:N_test, :N_SEQ_FEATURES]\n",
    "test_y = dataset[:N_test, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First model Baseline AVG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred for baseline:  5.632142857142857\n"
     ]
    }
   ],
   "source": [
    "baseline_prediction = train_y.mean()\n",
    "\n",
    "print(\"Pred for baseline: \", baseline_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6701626275510203"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((val_y - baseline_prediction)**2).sum()/val_y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([4,4,4,4])/np.array([2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.max(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15.6    ,   1.58   ,   0.79   ,  15.5    ,   0.611  ,  72.     ,\n",
       "       289.     ,   1.00369,   4.01   ,   1.98   ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.7    , 0.12   , 0.     , 0.9    , 0.012  , 1.     , 6.     ,\n",
       "       0.99007, 2.88   , 0.37   ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max = train_X.max(axis=0)\n",
    "train_min = train_X.min(axis=0)\n",
    "\n",
    "Q_factor = 100\n",
    "\n",
    "train_X -= train_min\n",
    "train_X /= (train_max-train_min) * Q_factor\n",
    "\n",
    "val_X -= train_min\n",
    "val_X /= (train_max-train_min) * Q_factor\n",
    "\n",
    "test_X -= train_min\n",
    "test_X /= (train_max-train_min) * Q_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First model Regresion\n",
    "\n",
    "Y = W.X + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_N_DIMS = train_X.shape[1]\n",
    "B_N_DIMS = train_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(np.random.ranf((1, W_N_DIMS)), dtype='float32')\n",
    "b = tf.Variable(np.random.ranf((B_N_DIMS, 1)), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1, 10) dtype=float32, numpy=\n",
       "array([[0.84212846, 0.3948212 , 0.64913833, 0.29011744, 0.505506  ,\n",
       "        0.8147143 , 0.3300597 , 0.29872987, 0.47734326, 0.688361  ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1120, 1) dtype=float32, numpy=\n",
       "array([[0.7455349 ],\n",
       "       [0.26478243],\n",
       "       [0.39630336],\n",
       "       ...,\n",
       "       [0.45274028],\n",
       "       [0.3571946 ],\n",
       "       [0.6819259 ]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_tensor = tf.constant(train_X, dtype='float32')\n",
    "train_y_tensor = tf.constant(train_y, dtype='float32')\n",
    "\n",
    "val_x_tensor = tf.constant(val_X, dtype='float32')\n",
    "val_y_tensor = tf.constant(val_y, dtype='float32')\n",
    "\n",
    "test_x_tensor = tf.constant(test_X, dtype='float32')\n",
    "test_y_tensor = tf.constant(test_y, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W (1, DIM) * X (N, DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try random values first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.matmul(W, tf.transpose(train_x_tensor)) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=27.74398>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_mean(tf.pow(tf.subtract(y, train_y_tensor), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with gradien tape to fix the weights\n",
    "\n",
    "Problems I ran into\n",
    "\n",
    "- I got none because I have declared W and b as constants!!! derivative is 0!\n",
    "- Im getting nan an inf!!?\n",
    "    - Standarizing values too small result in some of them being too big I had to adjust that (max-min) by Q=100\n",
    "- Mac tensorflow cant work with float16!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    y = tf.matmul(train_x_tensor, tf.transpose(W)) + b\n",
    "    loss = tf.math.reduce_mean(tf.pow(tf.subtract(y, train_y_tensor), 2))\n",
    "\n",
    "gradient_loss_w_b = tape.gradient(loss, [W, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W [1, 11]\n",
    "train_x_tensor[1120, 11]\n",
    "\n",
    "W*train_x_tensor [1120, 1]\n",
    "\n",
    "b [1120, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([-4.3158811e-03, -8.2727749e-04,  0.0000000e+00, -6.1686028e-04,\n",
       "       -2.0335267e-04, -1.4086490e-04, -2.1202162e-04, -1.2592443e+00,\n",
       "       -2.5711842e-02, -2.3123941e-03], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([0.84212846, 0.3948212 , 0.64913833, 0.29011744, 0.505506  ,\n",
       "       0.8147143 , 0.3300597 , 0.29872987, 0.47734326, 0.688361  ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.7455349], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3efa3519954fd4a9549d5070bd4bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Loss:  tf.Tensor(27.51944, shape=(), dtype=float32)\n",
      "First sample training set prediction [0.4466024] - real value 6.0\n",
      "TRAIN Loss:  tf.Tensor(19.419973, shape=(), dtype=float32)\n",
      "First sample training set prediction [6.664195] - real value 6.0\n",
      "TRAIN Loss:  tf.Tensor(18.736078, shape=(), dtype=float32)\n",
      "First sample training set prediction [6.661855] - real value 6.0\n",
      "TRAIN Loss:  tf.Tensor(18.077152, shape=(), dtype=float32)\n",
      "First sample training set prediction [6.6449947] - real value 6.0\n",
      "TRAIN Loss:  tf.Tensor(17.442245, shape=(), dtype=float32)\n",
      "First sample training set prediction [6.6283207] - real value 6.0\n"
     ]
    }
   ],
   "source": [
    "#init params\n",
    "W = tf.Variable(np.random.ranf((1, W_N_DIMS)), dtype='float32')\n",
    "b = tf.Variable(np.random.ranf((B_N_DIMS, 1)), dtype='float32')\n",
    "\n",
    "#init epsilon\n",
    "epsilon = tf.constant(0.01, dtype='float32')\n",
    "\n",
    "for epoc in tqdm(range(5000)):\n",
    "    # Feed-forward pass\n",
    "    with tf.GradientTape() as tape:\n",
    "        y = tf.matmul(train_x_tensor, tf.transpose(W)) + b\n",
    "        loss = tf.reduce_mean(tf.square(train_y_tensor-y))\n",
    "\n",
    "    if epoc%1000==0:\n",
    "        print(\"TRAIN Loss: \", loss)\n",
    "        print(f\"First sample training set prediction {y[0]} - real value {train_y_tensor[0]}\")\n",
    "\n",
    "    #backward - pass\n",
    "    w_grad, b_grad = tape.gradient(loss, [W, b])\n",
    "\n",
    "    W.assign_sub(epsilon*w_grad)\n",
    "    b.assign_sub(epsilon*b_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch approach is faster to converge\n",
    "\n",
    "as it is able to adjust weights faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2833b6be0fad46c8895b07853a446e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advance: 0.0%\n",
      "TRAIN Loss:  tf.Tensor(23.179642, shape=(), dtype=float32)\n",
      "VAL loss:  tf.Tensor(15.773583, shape=(), dtype=float32)\n",
      "First sample training set prediction [0.62152916] - real value 6.0\n",
      "advance: 20.0%\n",
      "TRAIN Loss:  tf.Tensor(0.5936506, shape=(), dtype=float32)\n",
      "VAL loss:  tf.Tensor(0.6071366, shape=(), dtype=float32)\n",
      "First sample training set prediction [5.6435504] - real value 6.0\n",
      "advance: 40.0%\n",
      "TRAIN Loss:  tf.Tensor(0.5936593, shape=(), dtype=float32)\n",
      "VAL loss:  tf.Tensor(0.6071228, shape=(), dtype=float32)\n",
      "First sample training set prediction [5.6434584] - real value 6.0\n",
      "advance: 60.0%\n",
      "TRAIN Loss:  tf.Tensor(0.59366196, shape=(), dtype=float32)\n",
      "VAL loss:  tf.Tensor(0.60710907, shape=(), dtype=float32)\n",
      "First sample training set prediction [5.6433983] - real value 6.0\n",
      "advance: 80.0%\n",
      "TRAIN Loss:  tf.Tensor(0.5936788, shape=(), dtype=float32)\n",
      "VAL loss:  tf.Tensor(0.6070962, shape=(), dtype=float32)\n",
      "First sample training set prediction [5.643373] - real value 6.0\n"
     ]
    }
   ],
   "source": [
    "#init params\n",
    "BATCH_SIZE = 32\n",
    "W = tf.Variable(np.random.ranf((1, W_N_DIMS)), dtype='float32')\n",
    "b = tf.Variable(np.random.ranf((BATCH_SIZE, 1)), dtype='float32')\n",
    "MAX_EPOCHS = 5000\n",
    "\n",
    "#init epsilon\n",
    "epsilon = tf.constant(0.01, dtype='float32')\n",
    "\n",
    "for epoc in tqdm(range(MAX_EPOCHS)):\n",
    "    \n",
    "    # Feed-forward pass\n",
    "    for batch in range(0, B_N_DIMS, BATCH_SIZE):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y = tf.matmul(train_x_tensor[batch:batch+BATCH_SIZE], tf.transpose(W)) + b\n",
    "            loss = tf.reduce_mean(tf.square(train_y_tensor[batch:batch+BATCH_SIZE]-y))\n",
    "        \n",
    "        #backward - pass\n",
    "        w_grad, b_grad = tape.gradient(loss, [W, b])\n",
    "\n",
    "        W.assign_sub(epsilon*w_grad)\n",
    "        b.assign_sub(epsilon*b_grad)\n",
    "\n",
    "    if epoc%1000==0:\n",
    "        print(f\"advance: {np.round(epoc/MAX_EPOCHS, 2)*100}%\")\n",
    "        val_loss = 0\n",
    "        for batch in range(0, val_x_tensor.shape[0], BATCH_SIZE):\n",
    "            y_val = tf.matmul(val_x_tensor[batch:batch+BATCH_SIZE], tf.transpose(W)) + b\n",
    "            val_loss += tf.reduce_mean(tf.square(val_y_tensor[batch:batch+BATCH_SIZE]-y_val))\n",
    "        print(\"TRAIN Loss: \", loss)\n",
    "        print(\"VAL loss: \", val_loss/(int(val_x_tensor.shape[0]/BATCH_SIZE)+1))\n",
    "        print(f\"First sample training set prediction {y[0]} - real value {train_y_tensor[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch with momemtum\n",
    "\n",
    "# With RMS to avoid getting stuck in a local minima around [0.557] en val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3401ce7908e145f188f9352d176fcb44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advance: 0.0%\n",
      "TRAIN Loss:  tf.Tensor(26.068678, shape=(), dtype=float32)\n",
      "VAL loss:  tf.Tensor(15.618469, shape=(), dtype=float32)\n",
      "First sample training set prediction [0.8675574] - real value 6.0\n",
      "advance: 0.2%\n",
      "TRAIN Loss:  tf.Tensor(0.6522009, shape=(), dtype=float32)\n",
      "VAL loss:  tf.Tensor(0.60857123, shape=(), dtype=float32)\n",
      "First sample training set prediction [5.6283174] - real value 6.0\n",
      "advance: 0.4%\n",
      "TRAIN Loss:  tf.Tensor(0.65220076, shape=(), dtype=float32)\n",
      "VAL loss:  tf.Tensor(0.6085788, shape=(), dtype=float32)\n",
      "First sample training set prediction [5.628383] - real value 6.0\n",
      "advance: 0.6%\n",
      "TRAIN Loss:  tf.Tensor(0.65220064, shape=(), dtype=float32)\n",
      "VAL loss:  tf.Tensor(0.6085862, shape=(), dtype=float32)\n",
      "First sample training set prediction [5.628398] - real value 6.0\n",
      "advance: 0.8%\n",
      "TRAIN Loss:  tf.Tensor(0.6522005, shape=(), dtype=float32)\n",
      "VAL loss:  tf.Tensor(0.6085936, shape=(), dtype=float32)\n",
      "First sample training set prediction [5.628371] - real value 6.0\n"
     ]
    }
   ],
   "source": [
    "#init params\n",
    "BATCH_SIZE = 32\n",
    "MAX_EPOCHS = 5000\n",
    "\n",
    "W = tf.Variable(np.random.ranf((1, W_N_DIMS)), dtype='float32')\n",
    "b = tf.Variable(np.random.ranf((BATCH_SIZE, 1)), dtype='float32')\n",
    "\n",
    "#RMS\n",
    "velocity_w = tf.Variable(np.zeros((1, W_N_DIMS)), dtype='float32')\n",
    "velocity_b = tf.Variable(np.zeros((BATCH_SIZE, 1)), dtype='float32')\n",
    "past_velocity_w = tf.Variable(np.zeros((1, W_N_DIMS)), dtype='float32')\n",
    "past_velocity_b = tf.Variable(np.zeros((BATCH_SIZE, 1)), dtype='float32')\n",
    "momentum = tf.constant(0.1, dtype='float32')\n",
    "\n",
    "#init epsilon\n",
    "epsilon = tf.constant(0.01, dtype='float32')\n",
    "\n",
    "for epoc in tqdm(range(MAX_EPOCHS)):\n",
    "    # Feed-forward pass\n",
    "    for batch in range(0, B_N_DIMS, BATCH_SIZE):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # print(f\"Range: {batch} , {batch+BATCH_SIZE}\")\n",
    "            y = tf.matmul(train_x_tensor[batch:batch+BATCH_SIZE], tf.transpose(W)) + b\n",
    "            loss = tf.reduce_mean(tf.square(train_y_tensor-y))\n",
    " \n",
    "        #backward - pass\n",
    "        w_grad, b_grad = tape.gradient(loss, [W, b])\n",
    "\n",
    "        velocity_w.assign(past_velocity_w*momentum-epsilon*w_grad)\n",
    "        velocity_b.assign(past_velocity_b*momentum-epsilon*b_grad)\n",
    "\n",
    "        W.assign_add(velocity_w*momentum-epsilon*w_grad)\n",
    "        b.assign_add(velocity_b*momentum-epsilon*b_grad)\n",
    "\n",
    "        past_velocity_w.assign(velocity_w)\n",
    "        past_velocity_b.assign(velocity_b)\n",
    "\n",
    "    if epoc%1000==0:\n",
    "        print(f\"advance: {np.round(epoc/MAX_EPOCHS, 2)}%\")\n",
    "        val_loss = 0\n",
    "        for batch in range(0, val_x_tensor.shape[0], BATCH_SIZE):\n",
    "            y_val = tf.matmul(val_x_tensor[batch:batch+BATCH_SIZE], tf.transpose(W)) + b\n",
    "            val_loss += tf.reduce_mean(tf.square(val_y_tensor[batch:batch+BATCH_SIZE]-y_val))\n",
    "        print(\"TRAIN Loss: \", loss)\n",
    "        print(\"VAL loss: \", val_loss/(int(val_x_tensor.shape[0]/BATCH_SIZE)+1))\n",
    "        print(f\"First sample training set prediction {y[0]} - real value {train_y_tensor[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tfm1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f45a28bef2cd7b14a523486f268164f58d5d2723d2e443d5e469c6699d63bc1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
